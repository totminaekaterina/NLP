{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yargy_parser_for_extracting_facts.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/totminaekaterina/NLP/blob/main/Yargy_parser_for_extracting_facts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipymarkup\n",
        "!pip install yargy"
      ],
      "metadata": {
        "id": "LfhYrAjLe8C7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24062061-1b4f-4c28-c2b9-a3ae8a6b99fc"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipymarkup in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
            "Requirement already satisfied: yargy in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from yargy) (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->yargy) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->yargy) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->yargy) (2.4.417127.4579844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yargy import Parser, rule, and_, or_"
      ],
      "metadata": {
        "id": "Q31LKTK9e82S"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yargy.predicates import (\n",
        "    eq, in_, dictionary,\n",
        "    type, gram, normalized)"
      ],
      "metadata": {
        "id": "UR9rUHlWe_JM"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yargy.interpretation import fact, attribute"
      ],
      "metadata": {
        "id": "-L4_ratsfBai"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipymarkup import show_box_markup\n",
        "from ipymarkup.palette import palette, RED, GREEN\n",
        "from ipymarkup import show_span_ascii_markup as show_markup"
      ],
      "metadata": {
        "id": "KP8WnfHKfDVm"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yargy.pipelines import morph_pipeline"
      ],
      "metadata": {
        "id": "pzmB4_pAfGRn"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "MRNdNfM-fIHI"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "D9NA8o-NUfLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1NXceWoUR20iL1k0RYvYJwTp1fOyyIVig"
      ],
      "metadata": {
        "id": "Ab4SABPxLyBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fa383a-b933-4c88-d18a-48ed98d6a4d6"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NXceWoUR20iL1k0RYvYJwTp1fOyyIVig\n",
            "To: /content/texts.txt\n",
            "\r  0% 0.00/4.24k [00:00<?, ?B/s]\r100% 4.24k/4.24k [00:00<00:00, 4.93MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "FaHYaAHCUWeS"
      },
      "outputs": [],
      "source": [
        "from random import seed, sample\n",
        "\n",
        "\n",
        "def load_lines(path):\n",
        "    with open(path) as file:\n",
        "        for line in file:\n",
        "            yield line.rstrip('\\n')\n",
        "\n",
        "            \n",
        "def make_translation_table(source, target):\n",
        "    assert len(source) == len(target)\n",
        "    return {\n",
        "        ord(a): ord(b)\n",
        "        for a, b in zip(source, target)\n",
        "    }\n",
        "\n",
        "\n",
        "DASHES_TRANSLATION = make_translation_table(\n",
        "    '‑–—−',\n",
        "    '----'\n",
        ")\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    return text.translate(DASHES_TRANSLATION)\n",
        "\n",
        "\n",
        "texts = [\n",
        "    normalize_text(_)\n",
        "    for _ in load_lines('texts.txt')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "from ipymarkup import show_span_ascii_markup as show_markup\n",
        "\n",
        "from yargy import (\n",
        "    Parser,\n",
        "    rule, or_,\n",
        "    not_, and_\n",
        ")\n",
        "from yargy.predicates import (\n",
        "    eq, type, caseless, in_, in_caseless,\n",
        "    gte, lte, length_eq,\n",
        "    is_capitalized, normalized,\n",
        "    dictionary, gram,\n",
        ")\n",
        "from yargy.pipelines import (\n",
        "    caseless_pipeline,\n",
        "    morph_pipeline\n",
        ")\n",
        "from yargy.interpretation import (\n",
        "    fact,\n",
        "    attribute\n",
        ")\n",
        "from yargy import interpretation as interp\n",
        "from yargy.relations import gnc_relation\n",
        "from yargy.tokenizer import (\n",
        "    QUOTES,\n",
        "    LEFT_QUOTES,\n",
        "    RIGHT_QUOTES,\n",
        "\n",
        "    MorphTokenizer,\n",
        "    TokenRule\n",
        ")"
      ],
      "metadata": {
        "id": "7TjAVg8hfWmQ"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_json(data):\n",
        "    print(json.dumps(data, indent=2, ensure_ascii=False))\n",
        "\n",
        "\n",
        "def test_interpretation(rule, *tests):\n",
        "    parser = Parser(rule)\n",
        "    for line, etalon in tests:\n",
        "        match = parser.match(line)\n",
        "        assert match, line\n",
        "        guess = match.fact\n",
        "        assert etalon == guess, guess\n",
        "        \n",
        "\n",
        "def test_match(rule, *tests):\n",
        "    parser = Parser(rule)\n",
        "    for line in tests:\n",
        "        match = parser.match(line)\n",
        "        assert match, line"
      ],
      "metadata": {
        "id": "k7pObJdMe2L-"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#COMMON"
      ],
      "metadata": {
        "id": "zBsBhcFUsbml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INT = type('INT')\n",
        "LATIN = type('LATIN')\n",
        "DOT = eq('.')\n",
        "DASH = eq('-')"
      ],
      "metadata": {
        "id": "X07VkuSAsNqH"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAIN TYPE"
      ],
      "metadata": {
        "id": "YzBXPa2i2k_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_TYPE = morph_pipeline([\n",
        "    'Название',\n",
        "    'Текст',\n",
        "    'Речь'\n",
        "]).interpretation(\n",
        "    interp.normalized()\n",
        ")"
      ],
      "metadata": {
        "id": "J4SjOyio2ks_"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ORGANISATION"
      ],
      "metadata": {
        "id": "PFqcmYUEjqLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUOTE = in_(QUOTES)\n",
        "LEFT_QUOTE = in_(LEFT_QUOTES)\n",
        "RIGHT_QUOTE = in_(RIGHT_QUOTES)\n",
        "\n",
        "ORGANISATION = or_(\n",
        "    rule(\n",
        "        LEFT_QUOTE,\n",
        "        not_(RIGHT_QUOTE).repeatable(),\n",
        "        RIGHT_QUOTE,\n",
        "    ),\n",
        "    rule(\n",
        "        and_(\n",
        "            QUOTE,\n",
        "            not_(RIGHT_QUOTE)\n",
        "        ),\n",
        "        not_(QUOTE).repeatable(),\n",
        "        and_(\n",
        "            QUOTE,\n",
        "            not_(LEFT_QUOTE)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "test_match(\n",
        "    ORGANISATION,\n",
        "    '\"Газпромнефть - НГУ\"',\n",
        "    '\"Газпром нефти\"',\n",
        "    '\"GeoHack\"',\n",
        "    '\"РНФ\"'\n",
        ")"
      ],
      "metadata": {
        "id": "7U3NfOLosiMP"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EVENT"
      ],
      "metadata": {
        "id": "3T_qeBX170ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Event = fact(\n",
        "    'Event',\n",
        "    ['type']\n",
        ")\n",
        "\n",
        "\n",
        "TYPE = morph_pipeline([\n",
        "    'магистерская программа',\n",
        "    'зимняя школа',\n",
        "    'региональный конкурс грантов',\n",
        "    'НОЦ'\n",
        "]).interpretation(\n",
        "    Event.type.normalized()\n",
        ")\n",
        "\n",
        "\n",
        "EVENT = rule(\n",
        "    TYPE.optional(),\n",
        ").interpretation(\n",
        "    Event\n",
        ")\n",
        "\n",
        "\n",
        "test_interpretation(\n",
        "    EVENT,\n",
        "    ['магистерские программы', Event(type='магистерская программа')],\n",
        "    ['зимняя школа', Event(type='зимняя школа')],\n",
        "    ['региональном конкурсе грантов', Event(type='региональный конкурс грантов')],\n",
        "    ['НОЦ', Event(type='НОЦ')]\n",
        ")"
      ],
      "metadata": {
        "id": "ByTJd4tVj3LP"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NAME"
      ],
      "metadata": {
        "id": "TBkHun_6v_5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Name = fact(\n",
        "    'Name',\n",
        "    ['first', 'middle', 'last']\n",
        ")\n",
        "\n",
        "\n",
        "gnc = gnc_relation()\n",
        "\n",
        "LAST = and_(\n",
        "    type('RU'),\n",
        "    is_capitalized()\n",
        ").interpretation(\n",
        "    Name.last.inflected()\n",
        ").match(gnc)\n",
        "\n",
        "FIRST = gram('Name').interpretation(\n",
        "    Name.first.inflected()\n",
        ").match(gnc)\n",
        "\n",
        "MIDDLE = gram('Patr').interpretation(\n",
        "    Name.middle.inflected()\n",
        ").match(gnc)\n",
        "\n",
        "ABBR = and_(\n",
        "    length_eq(1),\n",
        "    is_capitalized()\n",
        ")\n",
        "\n",
        "FIRST_ABBR = ABBR.interpretation(\n",
        "    Name.first.custom(str.lower)\n",
        ")\n",
        "\n",
        "MIDDLE_ABBR = ABBR.interpretation(\n",
        "    Name.middle.custom(str.lower)\n",
        ")\n",
        "\n",
        "\n",
        "NAME = or_(\n",
        "    rule(\n",
        "        LAST,\n",
        "        FIRST_ABBR, DOT,\n",
        "        MIDDLE_ABBR, DOT\n",
        "    ),\n",
        "    rule(\n",
        "        FIRST_ABBR, DOT,\n",
        "        MIDDLE_ABBR, DOT,\n",
        "        LAST\n",
        "    ),\n",
        "    rule(\n",
        "        LAST,\n",
        "        FIRST_ABBR, DOT\n",
        "    ),\n",
        "    rule(\n",
        "        FIRST_ABBR, DOT,\n",
        "        LAST\n",
        "    ),\n",
        "    rule(\n",
        "        FIRST,\n",
        "        MIDDLE,\n",
        "        LAST\n",
        "    ),\n",
        "    rule(\n",
        "        LAST,\n",
        "        FIRST,\n",
        "        MIDDLE\n",
        "    ),\n",
        "    rule(\n",
        "        FIRST,\n",
        "        LAST\n",
        "    ),\n",
        ").interpretation(\n",
        "    Name\n",
        ")\n",
        "\n",
        "\n",
        "test_interpretation(\n",
        "    NAME,\n",
        "    ['Алексей Вашкевич', Name(first='алексей', last='вашкевич')],\n",
        "    ['Дмитрия Новикова', Name(first='дмитрий', last='новиков')]\n",
        ")"
      ],
      "metadata": {
        "id": "jU6IECvcv4gu"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PERSON"
      ],
      "metadata": {
        "id": "Z0MgHk_ow4tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Person = fact(\n",
        "    'Person',\n",
        "    ['type', 'name']\n",
        ")\n",
        "\n",
        "\n",
        "TYPE = morph_pipeline([\n",
        "    'ведущий научный сотрудник',\n",
        "    'директор по технологическому развитию'\n",
        "]).interpretation(\n",
        "    Person.type.normalized()\n",
        ")\n",
        "\n",
        "PERSON = or_(\n",
        "    NAME,\n",
        "    TYPE\n",
        ").interpretation(\n",
        "    Person.name\n",
        ")\n",
        "\n",
        "PERSON = rule(\n",
        "    TYPE.optional(),\n",
        "    PERSON\n",
        ").interpretation(\n",
        "    Person\n",
        ")\n",
        "\n",
        "\n",
        "test_interpretation(\n",
        "    PERSON,\n",
        "    [ 'директор по технологическому развитию Алексей Вашкевич',\n",
        "        Person(type='директор по технологическому развитию', name=Name(first='алексей', last='вашкевич'))\n",
        "    ],\n",
        "    ['ведущего научного сотрудника Дмитрия Новикова',\n",
        "        Person(type='ведущий научный сотрудник', name=Name(first='дмитрий', last='новиков'))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "YNd8Vta8xDjx"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATE"
      ],
      "metadata": {
        "id": "v9gEP1_uy9hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Date = fact(\n",
        "    'Date',\n",
        "    ['year', 'month', 'day']\n",
        ")\n",
        "\n",
        "\n",
        "MONTHS = {\n",
        "    'январь': 1,\n",
        "    'февраль': 2,\n",
        "    'март': 3,\n",
        "    'апрель': 4,\n",
        "    'май': 5,\n",
        "    'июнь': 6,\n",
        "    'июль': 7,\n",
        "    'август': 8,\n",
        "    'сентябрь': 9,\n",
        "    'октябрь': 10,\n",
        "    'ноябрь': 11,\n",
        "    'декабрь': 12,\n",
        "}\n",
        "\n",
        "MONTH_NAME = dictionary(MONTHS).interpretation(\n",
        "    Date.month.normalized().custom(MONTHS.get)\n",
        ")\n",
        "\n",
        "MONTH = and_(\n",
        "    INT,\n",
        "    gte(1),\n",
        "    lte(12)\n",
        ").interpretation(\n",
        "    Date.month.custom(int)\n",
        ")\n",
        "\n",
        "YEAR = and_(\n",
        "    INT,\n",
        "    gte(1000),\n",
        "    lte(3000)\n",
        ").interpretation(\n",
        "    Date.year.custom(int)\n",
        ")\n",
        "\n",
        "YEAR_SUFFIX = rule(\n",
        "    or_(\n",
        "        eq('г'),\n",
        "        normalized('году')\n",
        "    ),\n",
        "    DOT.optional()\n",
        ")\n",
        "\n",
        "DAY = and_(\n",
        "    INT,\n",
        "    gte(1),\n",
        "    lte(31)\n",
        ").interpretation(\n",
        "    Date.day.custom(int)\n",
        ")\n",
        "\n",
        "DATE = or_(\n",
        "    rule(\n",
        "        YEAR,\n",
        "        YEAR_SUFFIX\n",
        "    ),\n",
        "    rule(\n",
        "        MONTH_NAME,\n",
        "        YEAR\n",
        "    ),\n",
        "    rule(\n",
        "        DAY,\n",
        "        DOT,\n",
        "        MONTH,\n",
        "        DOT,\n",
        "        YEAR\n",
        "    ),\n",
        "    rule(\n",
        "        DAY,\n",
        "        MONTH_NAME,\n",
        "        YEAR\n",
        "    ),\n",
        "    rule(\n",
        "        DAY,\n",
        "        MONTH_NAME\n",
        "    )\n",
        "\n",
        ")\n",
        "\n",
        "SUFFIX = normalized('началось')\n",
        "\n",
        "DATE = rule(\n",
        "    DATE,\n",
        "    SUFFIX.optional()\n",
        ").interpretation(\n",
        "    Date\n",
        ")\n",
        "\n",
        "test_interpretation(\n",
        "    DATE,\n",
        "    ['2018 году', Date(year=2018)],\n",
        "    ['2021 года', Date(year=2021)],\n",
        "    ['31 января', Date(month=1, day=31)],\n",
        "    ['6 февраля ', Date(month=2, day=6)]\n",
        ")"
      ],
      "metadata": {
        "id": "YD1b1oFiy_0s"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK"
      ],
      "metadata": {
        "id": "LfSLPBVsZXTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Task = fact(\n",
        "    'Task',\n",
        "    ['action', 'object']\n",
        ")\n",
        "\n",
        "ACTION = morph_pipeline([\n",
        "    'создание',\n",
        "    'развитие',\n",
        "    'картирование',\n",
        "    'обработка',\n",
        "    'физическое и математическое моделирование',\n",
        "]).interpretation(\n",
        "    Task.action.normalized()\n",
        ")\n",
        "\n",
        "OBJECT = morph_pipeline([\n",
        "    'технологии геологического хранения углеводорода',\n",
        "    'портфель проектов в области CCUS',\n",
        "    'объекты захоронения СО2',\n",
        "    'инструменты контроля',\n",
        "    'сейсморазведочных данных',\n",
        "    'гидроразрыв пласта',\n",
        "    'цифровые двойники горных пород',\n",
        "]).interpretation(\n",
        "    Task.object.normalized()\n",
        ")\n",
        "\n",
        "\n",
        "TASK = rule(\n",
        "    ACTION,\n",
        "    OBJECT\n",
        ").interpretation(\n",
        "    Task\n",
        ")\n",
        "\n",
        "\n",
        "test_interpretation(\n",
        "    TASK,\n",
        "    ['созданию технологии геологического хранения углеводорода', Task(action='создание', object='технологии геологического хранения углеводорода')],\n",
        "    #['развивает портфель проектов в области CCUS', Task(action='развитие', object='портфель проектов в области CCUS')],\n",
        "    #['картированию объектов захоронения СО2 ', Task(action='картирование', object='объекты захоронения СО2')],\n",
        "    ['развитию инструментов контроля', Task(action='развитие', object='инструменты контроля')],\n",
        "    ['обработки сейсморазведочных данных', Task(action='обработка', object='сейсморазведочных данных')],\n",
        "    ['физического и математического моделирования гидроразрыва пласта', Task(action='физическое и математическое моделирование', object='гидроразрыв пласта')],\n",
        "    ['создания цифровых двойников горной породы', Task(action='создание', object='цифровые двойники горных пород')]\n",
        ")"
      ],
      "metadata": {
        "id": "5ADUyU0LZZrs"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FSEM"
      ],
      "metadata": {
        "id": "53rX6DB32OXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Item = fact(\n",
        "    'Item',\n",
        "    ['type',\n",
        "     'organisation',\n",
        "     'person',\n",
        "     'date',\n",
        "     'task']\n",
        ")\n",
        "\n",
        "Fsem = fact(\n",
        "    'Fsem',\n",
        "    [attribute('items').repeatable(), 'event']\n",
        ")\n",
        "\n",
        "\n",
        "ATTRIBUTE = or_(\n",
        "    ORGANISATION.interpretation(Item.organisation),\n",
        "    PERSON.interpretation(Item.person),\n",
        "    TASK.interpretation(Item.task),\n",
        "    DATE.interpretation(Item.date)\n",
        ")\n",
        "\n",
        "ITEM = rule(\n",
        "    MAIN_TYPE.interpretation(Item.type),\n",
        "    ATTRIBUTE.repeatable()\n",
        ").interpretation(\n",
        "    Item\n",
        ")\n",
        "\n",
        "FSEM = rule(\n",
        "    ITEM.interpretation(\n",
        "        Fsem.items\n",
        "    ).repeatable(),\n",
        "    EVENT.interpretation(\n",
        "        Fsem.event\n",
        "    )\n",
        ").interpretation(\n",
        "    Fsem\n",
        ")"
      ],
      "metadata": {
        "id": "SZaTDK9I2Q0d"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXTRACTOR"
      ],
      "metadata": {
        "id": "1_v8FtLP3R8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def join_spans(text, spans):\n",
        "    spans = sorted(spans)\n",
        "    return ' '.join(\n",
        "        text[start:stop]\n",
        "        for start, stop in spans\n",
        "    )\n",
        "\n",
        "\n",
        "class Match(object):\n",
        "    def __init__(self, fact, spans):\n",
        "        self.fact = fact\n",
        "        self.spans = spans\n",
        "\n",
        "\n",
        "DEBUG = or_(\n",
        "    MAIN_TYPE,\n",
        "    ORGANISATION,\n",
        "    PERSON,\n",
        "    DATE,\n",
        "    TASK\n",
        ")\n",
        "\n",
        "TOKENIZER = MorphTokenizer()\n",
        "\n",
        "class Extractor(object):\n",
        "    def __init__(self):\n",
        "        self.debug = Parser(DEBUG, tokenizer=TOKENIZER)\n",
        "        self.parser = Parser(FSEM, tokenizer=TOKENIZER)\n",
        "\n",
        "    def __call__(self, text):\n",
        "        matches = self.debug.findall(text)\n",
        "        spans = [_.span for _ in matches]\n",
        "\n",
        "        line = join_spans(text, spans)\n",
        "        matches = list(self.parser.findall(line))\n",
        "        fact = None\n",
        "        if matches:\n",
        "            match = matches[0]\n",
        "            fact = match.fact\n",
        "\n",
        "        return Match(fact, spans)\n",
        "\n",
        "    \n",
        "extractor = Extractor()\n",
        "\n",
        "seed()\n",
        "for text in texts:\n",
        "    match = extractor(text)\n",
        "    show_markup(text, match.spans)\n",
        "    if match.fact:\n",
        "        show_json(match.fact.as_json)"
      ],
      "metadata": {
        "id": "zY081TdY3Ugv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbae862c-a29c-49e4-d588-5ff56d2431cd"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Название. НОЦ «Газпромнефть-НГУ» получил награду за вклад в развитие \n",
            "────────      ──────────────────                                     \n",
            "инновационной экосистемы.\n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Название\",\n",
            "      \"organisation\": \"«Газпромнефть-НГУ»\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Научно-образовательный центр «Газпромнефть-НГУ» получил награду\n",
            "─────                               ──────────────────                \n",
            " от Научно-Технического «Центра Газпром нефти» за значительный вклад в\n",
            "                        ──────────────────────                        \n",
            " развитие инновационной экосистемы компании.\n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Центра Газпром нефти»\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Таким образом индустриальный партнер Новосибирского \n",
            "─────                                                      \n",
            "государственного университета выразил благодарность за выстраивание \n",
            "стратегии взаимодействия, создание и настройку операционной модели \n",
            "проектного офиса по взаимодействию с компанией внутри своей \n",
            "организации, а также расширение линейки необходимых услуг и сервисов \n",
            "по разным направлениям деятельности «Газпром нефти». \n",
            "                                    ───────────────  \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Газпром нефти»\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Развитие партнерской сети - один из важнейших фокусов «Газпром \n",
            "─────                                                        ─────────\n",
            "нефти». \n",
            "──────  \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Газпром нефти»\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Он направлен на раскрытие потенциала научно-исследовательских \n",
            "─────                                                                \n",
            "организаций для реализации технологических проектов компании.\n",
            "Речь. Все наши партнеры проанализировали свой потенциал и ресурсы, \n",
            "────                                                               \n",
            "сформировали продуктовую линейку, провели организационную \n",
            "трансформацию, создали проектные офисы и проработали стратегию \n",
            "развития взаимодействия с компанией. \n",
            "Речь. Это важные шаги, которые позволят раскрыть весь потенциал и \n",
            "────                                                              \n",
            "возможности университетов для решения задач нефтегазовой отрасли в \n",
            "рамках нашего  сотрудничества, - сообщил директор по технологическому \n",
            "                                         ─────────────────────────────\n",
            "развитию «Газпром нефти» Алексей Вашкевич.\n",
            "──────── ─────────────── ──────────────── \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Речь\",\n",
            "      \"organisation\": \"«Газпром нефти»\",\n",
            "      \"person\": {\n",
            "        \"name\": {\n",
            "          \"first\": \"алексей\",\n",
            "          \"last\": \"вашкевич\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Стратегическое партнерство НГУ и НТЦ «Газпром нефти»в научно-\n",
            "─────                                       ───────────────         \n",
            "исследовательской деятельности и образовательных проектах началось в \n",
            "2018 году. \n",
            "────────── \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Газпром нефти»\",\n",
            "      \"date\": {\n",
            "        \"year\": 2018\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Тогда же был создан НОЦ «Газпромнефть-НГУ» и открыты первые \n",
            "─────                          ──────────────────                  \n",
            "совместные магистерские программы. С 2021 года команда центра активно \n",
            "                                     ─────────                        \n",
            "развивает портфель проектов в области CCUS по созданию технологии \n",
            "                                              ────────────────────\n",
            "геологического хранения углеводорода, в том числе по картированию \n",
            "────────────────────────────────────                 ─────────────\n",
            "объектов захоронения СО2 на территории России. \n",
            "────────────────────────                       \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Газпромнефть-НГУ»\",\n",
            "      \"date\": {\n",
            "        \"year\": 2021\n",
            "      },\n",
            "      \"task\": {\n",
            "        \"action\": \"картирование\",\n",
            "        \"object\": \"объекты захоронения СО2\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Сегодня центр ведет работу по развитию инструментов контроля и \n",
            "─────                                ──────────────────────────────   \n",
            "обработки сейсморазведочных данных, физического и математического \n",
            "──────────────────────────────────  ──────────────────────────────\n",
            "моделирования гидроразрыва пласта, создания цифровых двойников горной \n",
            "─────────────────────────────────  ───────────────────────────────────\n",
            "породы.\n",
            "────── \n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"task\": {\n",
            "        \"action\": \"создание\",\n",
            "        \"object\": \"цифровые двойники горных пород\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Текст. Напомним, что с 31 января по 6 февраля при поддержке НОЦ \n",
            "─────                  ─────────    ─────────                   \n",
            "«Газпромнефть-НГУ» прошла зимняя школа нефтегазового инжиниринга \n",
            "──────────────────                                               \n",
            "«GeoHack», а проект ведущего научного сотрудника НОЦ «Газпромнефть - \n",
            "─────────           ────────────────────────────     ────────────────\n",
            "НГУ» Дмитрия Новикова победил (ссылка) в региональном конкурсе грантов\n",
            "──── ────────────────                                                 \n",
            " РНФ.\n",
            "{\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"Текст\",\n",
            "      \"organisation\": \"«Газпромнефть - НГУ»\",\n",
            "      \"person\": {\n",
            "        \"name\": {\n",
            "          \"first\": \"дмитрий\",\n",
            "          \"last\": \"новиков\"\n",
            "        }\n",
            "      },\n",
            "      \"date\": {\n",
            "        \"month\": 2,\n",
            "        \"day\": 6\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}
